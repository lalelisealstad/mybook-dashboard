{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/elisealstad/code/mybook-dashboard'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to same place ass app.py to import programs the same way as the app\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "if 'notebooks' in current_directory:\n",
    "    parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "    os.chdir(parent_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improt packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "# Import functions from apps folder\n",
    "# from apps.collect_data import *\n",
    "\n",
    "pd.set_option('max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooksgr = pd.read_csv(\"assets/goodreads_library_export.csv\")\n",
    "mybooksgr = mybooksgr.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "df = mybooksgr.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pachinko\n",
      "The Evening and the Morning (Kingsbridge, #0)\n",
      "All the Light We Cannot See\n",
      "1984\n",
      "Monkey Hunting: A Novel (Ballantine Reader's Circle)\n",
      "Animal Farm\n",
      "one\n",
      "one\n",
      "one\n",
      "one\n",
      "one\n",
      "one\n",
      "                                     Title        Author(s) Publish_Date  \\\n",
      "0  Pachinko (National Book Award Finalist)      Min Jin Lee   2017-02-07   \n",
      "1              The Evening and the Morning      Ken Follett   2020-09-15   \n",
      "2              All the Light We Cannot See    Anthony Doerr   2023-10-03   \n",
      "3                                     1984    George Orwell   2013-09-03   \n",
      "4                           Monkey Hunting  Cristina GarcÃ­a   2007-12-18   \n",
      "5                              Animal Farm    George Orwell         2009   \n",
      "\n",
      "                                         Description           ISBN  \\\n",
      "0  A New York Times Top Ten Book of the Year and ...  9781455563913   \n",
      "1  #1 New York Times Bestseller An Amazon Best Bo...  9781984882028   \n",
      "2  *COMING IN NOVEMBER AS A NETFLIX LIMITED SERIE...  9781668017340   \n",
      "3  A PBS Great American Read Top 100 Pick With ex...  9780547249643   \n",
      "4  In this deeply stirring novel, acclaimed autho...  9780307416100   \n",
      "5  This is a classic tale of humanity awash in to...  9781412811903   \n",
      "\n",
      "   Page_Count          Categories  Average_Rating  Rating_Count Language  \n",
      "0         604             Fiction             NaN           NaN       en  \n",
      "1         930             Fiction             NaN           NaN       en  \n",
      "2         560             Fiction             NaN           NaN       en  \n",
      "3         309             Fiction             4.5          80.0       en  \n",
      "4         290             Fiction             NaN           NaN       en  \n",
      "5         118  Literary Criticism             NaN           NaN       en  \n"
     ]
    }
   ],
   "source": [
    "# used to be fast but not anymore\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        await asyncio.sleep(1)\n",
    "        print(book_name)\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Use nest_asyncio to allow running asyncio in a notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Create an event loop\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    # Alternative 1 # 2.5  mins\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "    book_infos = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "\n",
    "    # alternative 2 \n",
    "    # # Introduce a delay of 0.1 seconds between requests\n",
    "    # book_infos = asyncio.run(asyncio.gather(*[get_book_info_wrapper(row) for _, row in df.iterrows()]))\n",
    "    \n",
    "    \n",
    "    ###########\n",
    "\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    for book_info in book_infos:\n",
    "        if book_info:\n",
    "            print('one')\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "from apps.api import api_key\n",
    "result = book_info_add(mybooksgr.tail(6), api_key)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "async def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    results = await asyncio.gather(*tasks)  # Corrected placement of await\n",
    "    \n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    # Extract the actual results from the list\n",
    "    for book_info in results:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "   \n",
    "from apps.api import api_key\n",
    "result = await book_info_add(mybooksgr.sample(5), api_key)  # Use await when calling the async function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finishe, creating dfd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "async def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        await asyncio.sleep(1)\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    results = await asyncio.gather(*tasks)  # Corrected placement of await\n",
    "    print('finishe, creating dfd')\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    # Extract the actual results from the list\n",
    "    for book_info in results:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(book_info_add(mybooksgr.sample(5), api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
