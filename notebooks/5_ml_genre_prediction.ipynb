{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting book genre from book description \n",
    "\n",
    "highly used resource: https://www.kaggle.com/code/prathameshgadekar/book-genre-prediction-nlp/notebook\n",
    "\n",
    "Selecting MUltinomialNB since their analysis evaluated that to be the best model for that dataset, and since I am using the same dataframe, as I have not been able to find other dataframes with both book description and genre, I find it appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import missingno as msno #For missing value visualization\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For NLP\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Modelling Purpose\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index',inplace = True,axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning unecessary text from the string \n",
    "Stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower() #Converting to lowerCase\n",
    "    # text = re.sub('[%s]' % re.escape(string.punctuation), ' ',text) #removing punctuation\n",
    "    \n",
    "    text_tokens = word_tokenize(text) #removing stopwords\n",
    "    tw = [word for word in text_tokens if not word in Stopwords]\n",
    "    text = (\" \").join(tw)\n",
    "    \n",
    "    splt = text.split(' ')\n",
    "    output = [x for x in splt if len(x) > 3] #removing words with length<=3\n",
    "    text = (\" \").join(output)\n",
    "    \n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text) #removing single character \n",
    "    text = re.sub('<.*?>+',' ',text) #removing HTML Tags\n",
    "    text = re.sub('\\n', ' ',text) #removal of new line characters\n",
    "    text = re.sub(r'\\s+', ' ',text) #removal of multiple spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].map(clean)\n",
    "data['title'] = data['title'].map(clean)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "\n",
    "def data_preprocessing(text):\n",
    "    tokens = word_tokenize(text) #Tokenization\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens] #Lemmetization\n",
    "    tokens = [SnowballStemmer(language = 'english').stem(word) for word in tokens] #Stemming\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['summary'] = data['summary'].apply(data_preprocessing)\n",
    "data['title'] = data['title'].apply(data_preprocessing)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "data['genre_vec'] = labelencoder.fit_transform(data['genre'])\n",
    "data['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder.inverse_transform(data['genre_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data['summary'])\n",
    "y = data['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "begin = time.time()\n",
    "model.fit(X_train,y_train)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"model.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(model, open(filename, \"wb\"))\n",
    "\n",
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# you can use loaded model to compute predictions\n",
    "y_predicted = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks = pd.read_pickle('../assets/my_books.pkl')\n",
    "mybooks = mybooks.query('Description.notna()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks['Description_cleaned'] = mybooks['Description'].apply(clean)\n",
    "\n",
    "# data preprocessing \n",
    "mybooks['Description'] = mybooks['Description'].apply(data_preprocessing)\n",
    "mybooks['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "nyX = cv.transform(mybooks['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = labelencoder.inverse_transform(genre)\n",
    "print(inv)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
