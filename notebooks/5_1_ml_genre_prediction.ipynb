{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting book genre from book description \n",
    "\n",
    "highly used resource: https://www.kaggle.com/code/prathameshgadekar/book-genre-prediction-nlp/notebook\n",
    "\n",
    "Selecting MUltinomialNB since their analysis evaluated that to be the best model for that dataset, and since I am using the same dataframe, as I have not been able to find other dataframes with both book description and genre, I find it appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import missingno as msno #For missing value visualization\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For NLP\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Modelling Purpose\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/elisealstad/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/data.csv')\n",
    "amazondf = pd.read_pickle('../assets/amazon_books_description.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index',inplace = True,axis = 1)\n",
    "data = data.rename(columns={'title':'Title', 'summary':'Description' })\n",
    "new_labels_data =  {'fantasy':\"Science Fiction & Fantasy\" ,\n",
    "                     'psychology': 'psychology and self-help'}\n",
    "data['genre'] = data['genre'].replace(new_labels_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Page_Count</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Rating_Count</th>\n",
       "      <th>Language</th>\n",
       "      <th>genre</th>\n",
       "      <th>Title_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's That</td>\n",
       "      <td>Colin Broderick</td>\n",
       "      <td>2013-05-07</td>\n",
       "      <td>A brutally honest and deeply affecting memoir ...</td>\n",
       "      <td>9780307716347</td>\n",
       "      <td>368.0</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Title        Author(s) Publish_Date  \\\n",
       "0  That's That  Colin Broderick   2013-05-07   \n",
       "\n",
       "                                         Description           ISBN  \\\n",
       "0  A brutally honest and deeply affecting memoir ...  9780307716347   \n",
       "\n",
       "   Page_Count                 Categories  Average_Rating  Rating_Count  \\\n",
       "0       368.0  Biography & Autobiography             NaN           NaN   \n",
       "\n",
       "  Language genre Title_org  \n",
       "0       en   NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazondf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data, amazondf])\n",
    "df = (\n",
    "    df.dropna(subset=['Description', 'genre'])\n",
    "    .filter(items=['Title', 'Description','genre'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6946, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning unecessary text from the string \n",
    "Stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower() #Converting to lowerCase\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ',text) #removing punctuation\n",
    "    \n",
    "    text_tokens = word_tokenize(text) #removing stopwords\n",
    "    tw = [word for word in text_tokens if not word in Stopwords]\n",
    "    text = (\" \").join(tw)\n",
    "    \n",
    "    splt = text.split(' ')\n",
    "    output = [x for x in splt if len(x) > 3] #removing words with length<=3\n",
    "    text = (\" \").join(output)\n",
    "    \n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text) #removing single character \n",
    "    text = re.sub('<.*?>+',' ',text) #removing HTML Tags\n",
    "    text = re.sub('\\n', ' ',text) #removal of new line characters\n",
    "    text = re.sub(r'\\s+', ' ',text) #removal of multiple spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "thriller                      1212\n",
       "Science Fiction & Fantasy     1010\n",
       "history                        736\n",
       "science                        647\n",
       "horror                         600\n",
       "crime                          500\n",
       "romance                        276\n",
       "psychology and self-help       258\n",
       "sports                         239\n",
       "travel                         212\n",
       "Biographies & Memoirs          173\n",
       "Business & Money               173\n",
       "Children's Books               169\n",
       "Politics & Social Sciences     160\n",
       "Cookbooks, Food & Wine         151\n",
       "Crafts, Hobbies & Home         146\n",
       "Health                         143\n",
       "Teen & YA                      141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Most common words in Science Fiction & Fantasy column:\n",
      "one: 1061\n",
      "world: 687\n",
      "new: 651\n",
      "king: 582\n",
      "time: 565\n",
      "two: 547\n",
      "find: 547\n",
      "back: 533\n",
      "also: 485\n",
      "life: 483\n",
      "\n",
      "\n",
      " Most common words in science column:\n",
      "one: 691\n",
      "time: 637\n",
      "world: 486\n",
      "earth: 464\n",
      "planet: 425\n",
      "new: 421\n",
      "ship: 403\n",
      "human: 375\n",
      "first: 343\n",
      "life: 337\n",
      "\n",
      "\n",
      " Most common words in crime column:\n",
      "one: 550\n",
      "murder: 450\n",
      "man: 378\n",
      "police: 326\n",
      "also: 314\n",
      "two: 313\n",
      "poirot: 297\n",
      "death: 295\n",
      "house: 280\n",
      "found: 280\n",
      "\n",
      "\n",
      " Most common words in history column:\n",
      "one: 682\n",
      "father: 578\n",
      "war: 468\n",
      "two: 442\n",
      "time: 441\n",
      "also: 439\n",
      "story: 428\n",
      "life: 415\n",
      "first: 412\n",
      "new: 410\n",
      "\n",
      "\n",
      " Most common words in horror column:\n",
      "one: 731\n",
      "anita: 541\n",
      "house: 453\n",
      "new: 404\n",
      "also: 403\n",
      "man: 385\n",
      "back: 383\n",
      "two: 371\n",
      "life: 365\n",
      "find: 347\n",
      "\n",
      "\n",
      " Most common words in thriller column:\n",
      "one: 1136\n",
      "new: 743\n",
      "two: 585\n",
      "life: 542\n",
      "less: 536\n",
      "man: 519\n",
      "alex: 485\n",
      "find: 438\n",
      "time: 436\n",
      "back: 420\n",
      "\n",
      "\n",
      " Most common words in psychology and self-help column:\n",
      "book: 216\n",
      "life: 194\n",
      "people: 152\n",
      "new: 146\n",
      "us: 142\n",
      "one: 120\n",
      "love: 116\n",
      "world: 94\n",
      "make: 87\n",
      "work: 86\n",
      "\n",
      "\n",
      " Most common words in romance column:\n",
      "love: 200\n",
      "one: 198\n",
      "new: 177\n",
      "life: 160\n",
      "less: 117\n",
      "world: 91\n",
      "man: 87\n",
      "book: 81\n",
      "family: 78\n",
      "never: 77\n",
      "\n",
      "\n",
      " Most common words in sports column:\n",
      "one: 154\n",
      "book: 129\n",
      "less: 104\n",
      "team: 100\n",
      "new: 91\n",
      "life: 84\n",
      "game: 83\n",
      "world: 79\n",
      "first: 70\n",
      "hockey: 66\n",
      "\n",
      "\n",
      " Most common words in travel column:\n",
      "travel: 137\n",
      "world: 116\n",
      "book: 79\n",
      "new: 79\n",
      "guide: 74\n",
      "city: 70\n",
      "life: 68\n",
      "people: 64\n",
      "one: 63\n",
      "journey: 58\n",
      "\n",
      "\n",
      " Most common words in Biographies & Memoirs column:\n",
      "life: 135\n",
      "one: 116\n",
      "story: 113\n",
      "new: 89\n",
      "world: 82\n",
      "book: 74\n",
      "history: 69\n",
      "man: 60\n",
      "family: 58\n",
      "years: 58\n",
      "\n",
      "\n",
      " Most common words in Cookbooks, Food & Wine column:\n",
      "recipes: 236\n",
      "book: 120\n",
      "food: 112\n",
      "cooking: 97\n",
      "new: 80\n",
      "cookbook: 74\n",
      "one: 73\n",
      "delicious: 63\n",
      "ingredients: 60\n",
      "dishes: 57\n",
      "\n",
      "\n",
      " Most common words in Children's Books column:\n",
      "book: 90\n",
      "new: 58\n",
      "kids: 41\n",
      "children: 41\n",
      "readers: 40\n",
      "time: 39\n",
      "books: 37\n",
      "fun: 30\n",
      "series: 30\n",
      "young: 29\n",
      "\n",
      "\n",
      " Most common words in Teen & YA column:\n",
      "life: 64\n",
      "new: 55\n",
      "one: 37\n",
      "book: 35\n",
      "world: 32\n",
      "story: 31\n",
      "young: 31\n",
      "school: 30\n",
      "girl: 24\n",
      "series: 24\n",
      "\n",
      "\n",
      " Most common words in Health column:\n",
      "book: 90\n",
      "life: 67\n",
      "new: 59\n",
      "help: 58\n",
      "health: 50\n",
      "guide: 48\n",
      "treatment: 44\n",
      "information: 43\n",
      "well: 37\n",
      "body: 37\n",
      "\n",
      "\n",
      " Most common words in Crafts, Hobbies & Home column:\n",
      "book: 96\n",
      "new: 53\n",
      "guide: 50\n",
      "wedding: 39\n",
      "information: 38\n",
      "techniques: 38\n",
      "make: 32\n",
      "also: 31\n",
      "one: 31\n",
      "including: 30\n",
      "\n",
      "\n",
      " Most common words in Business & Money column:\n",
      "book: 134\n",
      "new: 120\n",
      "business: 113\n",
      "financial: 96\n",
      "edition: 70\n",
      "management: 69\n",
      "world: 65\n",
      "industry: 58\n",
      "market: 56\n",
      "work: 52\n",
      "\n",
      "\n",
      " Most common words in Politics & Social Sciences column:\n",
      "book: 109\n",
      "new: 95\n",
      "work: 66\n",
      "one: 66\n",
      "world: 58\n",
      "women: 55\n",
      "edition: 53\n",
      "philosophy: 47\n",
      "human: 39\n",
      "students: 37\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "def most_common_words(column, n=10):\n",
    "    # Tokenize and lowercase the words\n",
    "    words = word_tokenize(\" \".join(column.str.lower()))\n",
    "\n",
    "    # Remove stopwords (common words like 'the', 'and', etc.)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Calculate word frequencies\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    # Get the most common words\n",
    "    common_words = word_freq.most_common(n)\n",
    "\n",
    "    return common_words\n",
    "\n",
    "for genre in df.genre.unique().tolist(): \n",
    "    most_common_words_description = most_common_words(df.query('genre==@genre')['Description'], n=10)\n",
    "    print('\\n\\n',f\"Most common words in {genre} column:\")\n",
    "    for word, count in most_common_words_description:\n",
    "        print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "\n",
    "def data_preprocessing(text):\n",
    "    tokens = word_tokenize(text) #Tokenization\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens] #Lemmetization\n",
    "    tokens = [SnowballStemmer(language = 'english').stem(word) for word in tokens] #Stemming\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drowned Wednesday</td>\n",
       "      <td>drown wednesday is the first truste among the ...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lost Hero</td>\n",
       "      <td>as the book open , jason awaken on a school bu...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Eyes of the Overworld</td>\n",
       "      <td>cugel is easili persuad by the merchant fianos...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magic's Promise</td>\n",
       "      <td>the book open with herald-mag vanyel return to...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taran Wanderer</td>\n",
       "      <td>taran and gurgi have return to caer dallben fo...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Pretty Girls</td>\n",
       "      <td>lee child say it ’ s “ stunning… certain to be...</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>Go! All in One</td>\n",
       "      <td>this is the ebook of the print book and may no...</td>\n",
       "      <td>Business &amp; Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Who's There On Halloween?</td>\n",
       "      <td>who 's there on halloween ? encourag reader to...</td>\n",
       "      <td>Children's Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Foreclosure Investing For Dummies</td>\n",
       "      <td>make foreclosur invest work for you with this ...</td>\n",
       "      <td>Business &amp; Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>The Raven Room</td>\n",
       "      <td>a sear erot thriller perfect for those tantal ...</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6946 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                    Drowned Wednesday   \n",
       "1                        The Lost Hero   \n",
       "2            The Eyes of the Overworld   \n",
       "3                      Magic's Promise   \n",
       "4                       Taran Wanderer   \n",
       "..                                 ...   \n",
       "837                       Pretty Girls   \n",
       "838                     Go! All in One   \n",
       "839          Who's There On Halloween?   \n",
       "840  Foreclosure Investing For Dummies   \n",
       "841                     The Raven Room   \n",
       "\n",
       "                                           Description  \\\n",
       "0    drown wednesday is the first truste among the ...   \n",
       "1    as the book open , jason awaken on a school bu...   \n",
       "2    cugel is easili persuad by the merchant fianos...   \n",
       "3    the book open with herald-mag vanyel return to...   \n",
       "4    taran and gurgi have return to caer dallben fo...   \n",
       "..                                                 ...   \n",
       "837  lee child say it ’ s “ stunning… certain to be...   \n",
       "838  this is the ebook of the print book and may no...   \n",
       "839  who 's there on halloween ? encourag reader to...   \n",
       "840  make foreclosur invest work for you with this ...   \n",
       "841  a sear erot thriller perfect for those tantal ...   \n",
       "\n",
       "                         genre  \n",
       "0    Science Fiction & Fantasy  \n",
       "1    Science Fiction & Fantasy  \n",
       "2    Science Fiction & Fantasy  \n",
       "3    Science Fiction & Fantasy  \n",
       "4    Science Fiction & Fantasy  \n",
       "..                         ...  \n",
       "837                   thriller  \n",
       "838           Business & Money  \n",
       "839           Children's Books  \n",
       "840           Business & Money  \n",
       "841                    romance  \n",
       "\n",
       "[6946 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Description'] = df['Description'].apply(data_preprocessing)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7\n",
       "1       7\n",
       "2       7\n",
       "3       7\n",
       "4       7\n",
       "       ..\n",
       "837    16\n",
       "838     1\n",
       "839     2\n",
       "840     1\n",
       "841    13\n",
       "Name: genre_vec, Length: 6946, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df['genre_vec'] = labelencoder.fit_transform(df['genre'])\n",
    "df['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Science Fiction & Fantasy', 'Science Fiction & Fantasy',\n",
       "       'Science Fiction & Fantasy', ..., \"Children's Books\",\n",
       "       'Business & Money', 'romance'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder.inverse_transform(df['genre_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Description'])\n",
    "y = df['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different ML models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [BernoulliNB(),MultinomialNB(),SGDClassifier(),LogisticRegression(),RandomForestClassifier(),GradientBoostingClassifier(),\n",
    "         AdaBoostClassifier(),SVC(),DummyClassifier(),ExtraTreeClassifier(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Successfully Trained\n",
      "MultinomialNB Successfully Trained\n",
      "SGDClassifier Successfully Trained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elisealstad/Desktop/Code/mybook-dashboard/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Successfully Trained\n",
      "RandomForestClassifier Successfully Trained\n",
      "GradientBoostingClassifier Successfully Trained\n",
      "AdaBoostClassifier Successfully Trained\n",
      "SVC Successfully Trained\n",
      "DummyClassifier Successfully Trained\n",
      "ExtraTreeClassifier Successfully Trained\n",
      "KNeighborsClassifier Successfully Trained\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "Name = []\n",
    "Accuracy = []\n",
    "Precision = []\n",
    "F1_Score = []\n",
    "Recall = []\n",
    "Time_Taken = []\n",
    "for model in models:\n",
    "    name = type(model).__name__\n",
    "    Name.append(name)\n",
    "    begin = time.time()\n",
    "    model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    end = time.time()\n",
    "    Accuracy.append(accuracy_score(prediction,y_test))\n",
    "    Precision.append(precision_score(prediction,y_test,average = 'macro'))\n",
    "    Recall.append(recall_score(prediction, y_test, average='macro', zero_division=1))\n",
    "    F1_Score.append(f1_score(prediction,y_test,average = 'macro'))\n",
    "    Time_Taken.append(end-begin)\n",
    "    print(name + ' Successfully Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_score</th>\n",
       "      <th>Recall_score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.330935</td>\n",
       "      <td>0.137544</td>\n",
       "      <td>0.137544</td>\n",
       "      <td>0.133584</td>\n",
       "      <td>0.052388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.534532</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.351079</td>\n",
       "      <td>0.022617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.599281</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>0.538543</td>\n",
       "      <td>0.338006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.605036</td>\n",
       "      <td>0.551865</td>\n",
       "      <td>0.551865</td>\n",
       "      <td>0.557967</td>\n",
       "      <td>6.776117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.477698</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.380613</td>\n",
       "      <td>17.339131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.429237</td>\n",
       "      <td>0.429237</td>\n",
       "      <td>0.466317</td>\n",
       "      <td>351.766833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.298561</td>\n",
       "      <td>0.235048</td>\n",
       "      <td>0.235048</td>\n",
       "      <td>0.247421</td>\n",
       "      <td>9.825970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.360432</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>0.193885</td>\n",
       "      <td>0.197525</td>\n",
       "      <td>35.842732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.174101</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.213669</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>0.183106</td>\n",
       "      <td>0.320879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.177698</td>\n",
       "      <td>0.177698</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  Accuracy  Precision_score  Recall_score  \\\n",
       "0                  BernoulliNB  0.330935         0.137544      0.137544   \n",
       "1                MultinomialNB  0.534532         0.339410      0.339410   \n",
       "2                SGDClassifier  0.599281         0.535043      0.535043   \n",
       "3           LogisticRegression  0.605036         0.551865      0.551865   \n",
       "4       RandomForestClassifier  0.477698         0.359631      0.359631   \n",
       "5   GradientBoostingClassifier  0.530935         0.429237      0.429237   \n",
       "6           AdaBoostClassifier  0.298561         0.235048      0.235048   \n",
       "7                          SVC  0.360432         0.193885      0.193885   \n",
       "8              DummyClassifier  0.174101         0.055556      0.055556   \n",
       "9          ExtraTreeClassifier  0.213669         0.186854      0.186854   \n",
       "10        KNeighborsClassifier  0.215108         0.177698      0.177698   \n",
       "\n",
       "    F1_score  Time Taken  \n",
       "0   0.133584    0.052388  \n",
       "1   0.351079    0.022617  \n",
       "2   0.538543    0.338006  \n",
       "3   0.557967    6.776117  \n",
       "4   0.380613   17.339131  \n",
       "5   0.466317  351.766833  \n",
       "6   0.247421    9.825970  \n",
       "7   0.197525   35.842732  \n",
       "8   0.016476    0.000865  \n",
       "9   0.183106    0.320879  \n",
       "10  0.172192    0.430551  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict = {'Name':Name,'Accuracy':Accuracy,'Precision_score':Precision,'Recall_score':Precision,\n",
    "        'F1_score':F1_Score,'Time Taken':Time_Taken}\n",
    "model_df = pd.DataFrame(Dict)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run and store best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best fitting model \n",
    "model =LogisticRegression(max_iter=1000)\n",
    "model.fit(X,y)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"model.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(model, open(filename, \"wb\"))\n",
    "\n",
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# you can use loaded model to compute predictions\n",
    "y_predicted = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks = pd.read_pickle('../assets/my_books.pkl')\n",
    "mybooks = mybooks.query('Description.notna()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      japanes fairi tale - enchant , enigmat stori o...\n",
       "1      ' a sensual feast of a novel , written with el...\n",
       "2      a new york time , usa today , and washington p...\n",
       "3      * the sunday time number one bestsel * * over ...\n",
       "4      the addict no.1 bestsel that everyon is talk a...\n",
       "                             ...                        \n",
       "359    the key to rebecca is a grip thriller set dure...\n",
       "360    winner of the pulitz prize , a new york time b...\n",
       "361    one of the most influenti book of the twentiet...\n",
       "362    in this deepli stir novel , acclaim author cri...\n",
       "363    mr jone of manor farm is so lazi and drunken t...\n",
       "Name: Description, Length: 332, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybooks['Description_cleaned'] = mybooks['Description'].apply(clean)\n",
    "\n",
    "# data preprocessing \n",
    "mybooks['Description'] = mybooks['Description'].apply(data_preprocessing)\n",
    "mybooks['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "nyX = cv.transform(mybooks['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use loaded model to compute predictions\n",
    "genre = loaded_model.predict(nyX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Science Fiction & Fantasy' 'romance' 'Science Fiction & Fantasy'\n",
      " 'psychology and self-help' 'romance' 'travel' 'thriller' 'thriller'\n",
      " 'thriller' 'thriller' 'thriller' 'thriller' 'thriller'\n",
      " 'Science Fiction & Fantasy' 'travel' 'romance' 'romance' 'thriller'\n",
      " 'Teen & YA' 'thriller' 'thriller' 'thriller' 'thriller' 'thriller'\n",
      " 'thriller' 'thriller' 'thriller' 'thriller' 'Teen & YA' 'romance'\n",
      " 'romance' 'Science Fiction & Fantasy' 'Science Fiction & Fantasy'\n",
      " 'psychology and self-help' 'thriller' 'thriller' 'horror' 'romance'\n",
      " 'Science Fiction & Fantasy' 'romance' 'thriller' 'Cookbooks, Food & Wine'\n",
      " 'thriller' 'thriller' 'thriller' 'thriller' 'Science Fiction & Fantasy'\n",
      " 'thriller' 'Biographies & Memoirs' 'Science Fiction & Fantasy' 'travel'\n",
      " 'thriller' 'thriller' 'crime' 'thriller' 'Business & Money' 'thriller'\n",
      " 'thriller' 'romance' 'thriller' 'thriller' 'thriller' 'thriller'\n",
      " 'thriller' 'psychology and self-help' 'Teen & YA' 'romance'\n",
      " 'psychology and self-help' 'Business & Money' 'thriller' 'romance'\n",
      " 'romance' 'thriller' 'horror' 'travel' 'romance' 'thriller' 'science'\n",
      " 'history' 'thriller' 'sports' 'Business & Money' 'romance' 'horror'\n",
      " 'science' 'sports' 'romance' 'Science Fiction & Fantasy'\n",
      " 'psychology and self-help' 'travel' 'Science Fiction & Fantasy' 'romance'\n",
      " 'Teen & YA' 'Business & Money' 'thriller' 'Teen & YA' 'thriller'\n",
      " 'romance' 'Science Fiction & Fantasy' 'history' 'romance' 'travel'\n",
      " 'romance' 'thriller' 'romance' 'horror' 'Science Fiction & Fantasy'\n",
      " 'sports' 'romance' 'science' 'thriller' 'thriller' 'romance' 'thriller'\n",
      " 'thriller' 'Biographies & Memoirs' 'thriller' 'Business & Money'\n",
      " 'romance' 'romance' 'Teen & YA' 'thriller' 'Science Fiction & Fantasy'\n",
      " 'thriller' 'thriller' 'Science Fiction & Fantasy' 'thriller'\n",
      " 'psychology and self-help' \"Children's Books\" 'science' 'crime'\n",
      " 'thriller' 'romance' 'crime' 'Science Fiction & Fantasy' 'history'\n",
      " 'romance' 'Health' 'romance' 'Science Fiction & Fantasy' 'thriller'\n",
      " 'history' 'Science Fiction & Fantasy' 'romance' 'thriller' 'thriller'\n",
      " 'romance' 'science' 'thriller' 'thriller' 'thriller' 'romance' 'thriller'\n",
      " 'history' 'Teen & YA' 'history' \"Children's Books\" 'romance' 'thriller'\n",
      " 'science' 'thriller' 'romance' 'thriller' 'science'\n",
      " 'Biographies & Memoirs' 'thriller' 'thriller' 'thriller'\n",
      " 'Science Fiction & Fantasy' 'thriller' 'thriller'\n",
      " 'psychology and self-help' 'romance' 'Biographies & Memoirs' 'thriller'\n",
      " 'Science Fiction & Fantasy' 'Science Fiction & Fantasy' 'thriller'\n",
      " 'Science Fiction & Fantasy' 'thriller' 'psychology and self-help'\n",
      " 'history' 'romance' \"Children's Books\" 'Biographies & Memoirs'\n",
      " 'Science Fiction & Fantasy' 'thriller' 'Biographies & Memoirs'\n",
      " \"Children's Books\" 'romance' 'romance' 'history' 'thriller'\n",
      " \"Children's Books\" 'travel' 'travel' 'psychology and self-help' 'romance'\n",
      " 'travel' 'travel' 'travel' 'thriller' 'science' 'romance' 'thriller'\n",
      " 'thriller' \"Children's Books\" 'romance' 'travel' 'travel' 'thriller'\n",
      " 'romance' 'Cookbooks, Food & Wine' \"Children's Books\" 'romance'\n",
      " 'thriller' 'romance' 'travel' 'Science Fiction & Fantasy'\n",
      " 'Science Fiction & Fantasy' 'history' 'romance'\n",
      " 'Politics & Social Sciences' 'Science Fiction & Fantasy'\n",
      " 'Science Fiction & Fantasy' 'Science Fiction & Fantasy' 'travel'\n",
      " 'Teen & YA' 'thriller' \"Children's Books\" 'Science Fiction & Fantasy'\n",
      " 'thriller' 'Science Fiction & Fantasy' 'thriller'\n",
      " 'Science Fiction & Fantasy' 'thriller' 'travel' 'romance'\n",
      " \"Children's Books\" 'thriller' 'thriller' 'thriller' 'thriller' 'thriller'\n",
      " 'psychology and self-help' \"Children's Books\" 'Science Fiction & Fantasy'\n",
      " 'Biographies & Memoirs' 'Biographies & Memoirs' 'thriller' 'thriller'\n",
      " 'science' 'Biographies & Memoirs' 'crime' 'psychology and self-help'\n",
      " 'thriller' 'travel' 'thriller' 'thriller' 'thriller'\n",
      " 'psychology and self-help' 'psychology and self-help'\n",
      " 'psychology and self-help' 'psychology and self-help'\n",
      " 'psychology and self-help' 'romance' 'history'\n",
      " 'Science Fiction & Fantasy' 'Science Fiction & Fantasy'\n",
      " 'psychology and self-help' 'thriller' 'thriller' \"Children's Books\"\n",
      " 'science' 'psychology and self-help' 'Cookbooks, Food & Wine'\n",
      " 'Politics & Social Sciences' 'Business & Money'\n",
      " 'psychology and self-help' 'thriller' 'psychology and self-help'\n",
      " 'thriller' 'romance' 'Health' 'Crafts, Hobbies & Home'\n",
      " 'Crafts, Hobbies & Home' 'thriller' 'Biographies & Memoirs' 'science'\n",
      " 'travel' 'Biographies & Memoirs' 'thriller' 'thriller' 'thriller'\n",
      " 'Teen & YA' 'Science Fiction & Fantasy' 'thriller' 'Teen & YA' 'thriller'\n",
      " 'Biographies & Memoirs' 'thriller' 'crime' 'thriller'\n",
      " 'psychology and self-help' 'romance' 'Biographies & Memoirs' 'thriller'\n",
      " 'thriller' 'thriller' 'history' 'Politics & Social Sciences' 'romance'\n",
      " 'thriller' 'Science Fiction & Fantasy' 'romance' 'history' 'thriller'\n",
      " 'thriller' 'romance' 'travel' 'thriller' 'history' 'thriller' 'Teen & YA'\n",
      " 'crime' 'Biographies & Memoirs' 'history' 'thriller' 'thriller' 'science'\n",
      " 'travel' 'science']\n"
     ]
    }
   ],
   "source": [
    "inv = labelencoder.inverse_transform(genre)\n",
    "print(inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks['genre'] = inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Night Train to the Stars</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Language of Food</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The House in the Cerulean Sea</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Invisible Women: Data Bias in a World Designed...</td>\n",
       "      <td>psychology and self-help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gone Girl</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ute av verden</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Local Woman Missing</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Silent Patient</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Devotion of Suspect X (Detective Galileo, #1)</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Secret History</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Nightingale</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Girlfriend</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Coworker</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fahrenheit 451</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>De syv søstre</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A Tale for the Time Being</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Wind-Up Bird Chronicle</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Life Ceremony</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lonely Castle in the Mirror</td>\n",
       "      <td>Teen &amp; YA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Never Lie</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Family Upstairs (The Family Upstairs, #1)</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Everyone in My Family Has Killed Someone (Erne...</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Quiet Tenant</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Drowning Woman</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Then She Was Gone</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None of This Is True</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A Game of Lies (DC Morgan, #2)</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Housemaid (The Housemaid, #1)</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Prison Healer (The Prison Healer, #1)</td>\n",
       "      <td>Teen &amp; YA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Exodus (The Ravenhood, #2)</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Risk (Mindf*ck, #1)</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Serpent and the Wings of Night (Crowns of ...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A Broken Blade (The Halfling Saga, #1)</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Signs of Cupidity (Heart Hassle, #1)</td>\n",
       "      <td>psychology and self-help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The Inheritance Games (The Inheritance Games, #1)</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>A Good Girl's Guide to Murder (A Good Girl's G...</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Knock Knock, Open Wide</td>\n",
       "      <td>horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Boy Parts</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Maybe in Another Life</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>After I Do</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Conquest</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The Eighth Life: for Brilka</td>\n",
       "      <td>Cookbooks, Food &amp; Wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Yellowface</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bellies</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kala</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sunburn</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Fourth Wing (The Empyrean, #1)</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>The Only One Left</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Penance</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Carrie Soto Is Back</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                            Night Train to the Stars   \n",
       "1                                The Language of Food   \n",
       "2                       The House in the Cerulean Sea   \n",
       "3   Invisible Women: Data Bias in a World Designed...   \n",
       "4                                           Gone Girl   \n",
       "5                                       Ute av verden   \n",
       "6                                 Local Woman Missing   \n",
       "7                                  The Silent Patient   \n",
       "8   The Devotion of Suspect X (Detective Galileo, #1)   \n",
       "9                                  The Secret History   \n",
       "10                                    The Nightingale   \n",
       "11                                     The Girlfriend   \n",
       "12                                       The Coworker   \n",
       "13                                     Fahrenheit 451   \n",
       "14                                      De syv søstre   \n",
       "15                          A Tale for the Time Being   \n",
       "16                         The Wind-Up Bird Chronicle   \n",
       "17                                      Life Ceremony   \n",
       "18                        Lonely Castle in the Mirror   \n",
       "20                                          Never Lie   \n",
       "21      The Family Upstairs (The Family Upstairs, #1)   \n",
       "22  Everyone in My Family Has Killed Someone (Erne...   \n",
       "23                                   The Quiet Tenant   \n",
       "24                                 The Drowning Woman   \n",
       "25                                  Then She Was Gone   \n",
       "26                               None of This Is True   \n",
       "28                     A Game of Lies (DC Morgan, #2)   \n",
       "29                  The Housemaid (The Housemaid, #1)   \n",
       "30          The Prison Healer (The Prison Healer, #1)   \n",
       "32                         Exodus (The Ravenhood, #2)   \n",
       "33                            The Risk (Mindf*ck, #1)   \n",
       "34  The Serpent and the Wings of Night (Crowns of ...   \n",
       "35             A Broken Blade (The Halfling Saga, #1)   \n",
       "36               Signs of Cupidity (Heart Hassle, #1)   \n",
       "37  The Inheritance Games (The Inheritance Games, #1)   \n",
       "38  A Good Girl's Guide to Murder (A Good Girl's G...   \n",
       "39                             Knock Knock, Open Wide   \n",
       "41                                          Boy Parts   \n",
       "42                              Maybe in Another Life   \n",
       "43                                         After I Do   \n",
       "44                                           Conquest   \n",
       "45                        The Eighth Life: for Brilka   \n",
       "46                                         Yellowface   \n",
       "47                                            Bellies   \n",
       "48                                               Kala   \n",
       "49                                            Sunburn   \n",
       "51                     Fourth Wing (The Empyrean, #1)   \n",
       "52                                  The Only One Left   \n",
       "53                                            Penance   \n",
       "56                                Carrie Soto Is Back   \n",
       "\n",
       "                        genre  \n",
       "0   Science Fiction & Fantasy  \n",
       "1                     romance  \n",
       "2   Science Fiction & Fantasy  \n",
       "3    psychology and self-help  \n",
       "4                     romance  \n",
       "5                      travel  \n",
       "6                    thriller  \n",
       "7                    thriller  \n",
       "8                    thriller  \n",
       "9                    thriller  \n",
       "10                   thriller  \n",
       "11                   thriller  \n",
       "12                   thriller  \n",
       "13  Science Fiction & Fantasy  \n",
       "14                     travel  \n",
       "15                    romance  \n",
       "16                    romance  \n",
       "17                   thriller  \n",
       "18                  Teen & YA  \n",
       "20                   thriller  \n",
       "21                   thriller  \n",
       "22                   thriller  \n",
       "23                   thriller  \n",
       "24                   thriller  \n",
       "25                   thriller  \n",
       "26                   thriller  \n",
       "28                   thriller  \n",
       "29                   thriller  \n",
       "30                  Teen & YA  \n",
       "32                    romance  \n",
       "33                    romance  \n",
       "34  Science Fiction & Fantasy  \n",
       "35  Science Fiction & Fantasy  \n",
       "36   psychology and self-help  \n",
       "37                   thriller  \n",
       "38                   thriller  \n",
       "39                     horror  \n",
       "41                    romance  \n",
       "42  Science Fiction & Fantasy  \n",
       "43                    romance  \n",
       "44                   thriller  \n",
       "45     Cookbooks, Food & Wine  \n",
       "46                   thriller  \n",
       "47                   thriller  \n",
       "48                   thriller  \n",
       "49                   thriller  \n",
       "51  Science Fiction & Fantasy  \n",
       "52                   thriller  \n",
       "53      Biographies & Memoirs  \n",
       "56  Science Fiction & Fantasy  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybooks[['Title','genre']].head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "thriller                      114\n",
       "romance                        50\n",
       "Science Fiction & Fantasy      35\n",
       "psychology and self-help       21\n",
       "travel                         20\n",
       "history                        14\n",
       "Biographies & Memoirs          14\n",
       "science                        13\n",
       "Teen & YA                      11\n",
       "Children's Books               11\n",
       "crime                           6\n",
       "Business & Money                6\n",
       "horror                          4\n",
       "Cookbooks, Food & Wine          3\n",
       "sports                          3\n",
       "Politics & Social Sciences      3\n",
       "Health                          2\n",
       "Crafts, Hobbies & Home          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybooks.genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating prediction of model \n",
    "\n",
    "It seems like a lot of books are not predicted corretly and a majority of my books are predicted as thriller. I do read a lot of thrillers but the share is too big too be true. It does seem like the initival dataset used for prediction have a substantial share of thrillers, which may cause it too predict too many books as thrillers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model \n",
    "I will try and add another dataset for training, https://github.com/uchidalab/book-dataset/tree/master/Task2, which contains 270K books from amazon with title and category name. \n",
    "\n",
    "I will have to: \n",
    "- make sure common category names between two datasets are the same \n",
    "- remove some small and unecessary categories from the amazon dataframe. \n",
    "- collect description from google api in several rounds with max 49K books each time to now exceed limit of 50K per day. \n",
    "\n",
    "Model building: \n",
    "- use similar approach and test several models: https://www.kaggle.com/code/prathameshgadekar/book-genre-prediction-nlp/notebook\n",
    "- select best predicting model "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data cleaning - run once\n",
    "amazondf = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task2/book32-listing.csv\", \n",
    "    encoding='ISO-8859-1',\n",
    "    header=None, \n",
    "    names=[\"AMAZON INDEX (ASIN)}\",\"[FILENAME]\",\"[IMAGE URL]\",\"title\",\"author\",\"[CATEGORY ID]\",\"category\"])\n",
    "amazondf = amazondf[['title', 'author', 'category']] \n",
    "\n",
    "# I remove some categories I dont feel will be books added to GR (usually fiction) and some very small categories. \n",
    "\n",
    "new_labels = {\"Travel\"        : \"travel\",\n",
    "\"Children's Books\"            : \"Children's Books\"  ,\n",
    "\"Health, Fitness & Dieting\"   : \"Health\",\n",
    "\"Business & Money\"            : \"Business & Money\"  ,\n",
    "\"Crafts, Hobbies & Home\"      : \"Crafts, Hobbies & Home\" ,\n",
    "\"Cookbooks, Food & Wine\"      : \"Cookbooks, Food & Wine\"  ,\n",
    "\"Teen & Young Adult\"          : \"Teen & YA\",\n",
    "\"History\"                     : \"history\",\n",
    "\"Sports & Outdoors\"           : \"sports\",\n",
    "\"Romance\"                     : \"romance\",\n",
    "\"Biographies & Memoirs\"       : \"Biographies & Memoirs\",\n",
    "\"Science Fiction & Fantasy\"   : \"Science Fiction & Fantasy\",\n",
    "\"Politics & Social Sciences\"  : \"Politics & Social Sciences\",\n",
    "\"Self-Help\"                   : 'psychology and self-help' ,\n",
    "\"Mystery, Thriller & Suspense\": \"thriller\"}\n",
    "\n",
    "\n",
    "amazondf = amazondf.query('category in @new_labels')\n",
    "amazondf['category'] = amazondf['category'].replace(new_labels)\n",
    "\n",
    "amazondf = amazondf.rename(columns={'category':'genre', 'title':'Title', 'author':'Author'} )\n",
    "amazondf = amazondf.drop_duplicates(subset='Title', keep='first')\n",
    "\n",
    "amazondf.to_pickle('assets/amazon_books.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
