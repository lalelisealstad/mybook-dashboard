{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting book genre from book description \n",
    "\n",
    "highly used resource: https://www.kaggle.com/code/prathameshgadekar/book-genre-prediction-nlp/notebook\n",
    "\n",
    "Selecting MUltinomialNB since their analysis evaluated that to be the best model for that dataset, and since I am using the same dataframe, as I have not been able to find other dataframes with both book description and genre, I find it appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import missingno as msno #For missing value visualization\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For NLP\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Modelling Purpose\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/elisealstad/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/data.csv')\n",
    "amazondf = pd.read_pickle('../assets/amazon_books_description.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index',inplace = True,axis = 1)\n",
    "data = data.rename(columns={'title':'Title', 'summary':'Description' })\n",
    "new_labels_data =  {'fantasy':\"Science Fiction & Fantasy\" ,\n",
    "                     'psychology': 'psychology and self-help'}\n",
    "data['genre'] = data['genre'].replace(new_labels_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Page_Count</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Rating_Count</th>\n",
       "      <th>Language</th>\n",
       "      <th>genre</th>\n",
       "      <th>Title_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That's That</td>\n",
       "      <td>Colin Broderick</td>\n",
       "      <td>2013-05-07</td>\n",
       "      <td>A brutally honest and deeply affecting memoir ...</td>\n",
       "      <td>9780307716347</td>\n",
       "      <td>368.0</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Title        Author(s) Publish_Date  \\\n",
       "0  That's That  Colin Broderick   2013-05-07   \n",
       "\n",
       "                                         Description           ISBN  \\\n",
       "0  A brutally honest and deeply affecting memoir ...  9780307716347   \n",
       "\n",
       "   Page_Count                 Categories  Average_Rating  Rating_Count  \\\n",
       "0       368.0  Biography & Autobiography             NaN           NaN   \n",
       "\n",
       "  Language genre Title_org  \n",
       "0       en   NaN       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazondf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data, amazondf])\n",
    "df = (\n",
    "    df.dropna(subset=['Description', 'genre'])\n",
    "    .filter(items=['Title', 'Description','genre'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning unecessary text from the string \n",
    "Stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower() #Converting to lowerCase\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ',text) #removing punctuation\n",
    "    \n",
    "    text_tokens = word_tokenize(text) #removing stopwords\n",
    "    tw = [word for word in text_tokens if not word in Stopwords]\n",
    "    text = (\" \").join(tw)\n",
    "    \n",
    "    splt = text.split(' ')\n",
    "    output = [x for x in splt if len(x) > 3] #removing words with length<=3\n",
    "    text = (\" \").join(output)\n",
    "    \n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text) #removing single character \n",
    "    text = re.sub('<.*?>+',' ',text) #removing HTML Tags\n",
    "    text = re.sub('\\n', ' ',text) #removal of new line characters\n",
    "    text = re.sub(r'\\s+', ' ',text) #removal of multiple spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drowned Wednesday</td>\n",
       "      <td>drowned wednesday first trustee among morrow d...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lost Hero</td>\n",
       "      <td>book opens jason awakens school unable remembe...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Eyes of the Overworld</td>\n",
       "      <td>cugel easily persuaded merchant fianosther att...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magic's Promise</td>\n",
       "      <td>book opens herald mage vanyel returning countr...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taran Wanderer</td>\n",
       "      <td>taran gurgi returned caer dallben following ev...</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Pretty Girls</td>\n",
       "      <td>child says stunning… certain book year kathy r...</td>\n",
       "      <td>thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>Go! All in One</td>\n",
       "      <td>ebook printed book include media website acces...</td>\n",
       "      <td>Business &amp; Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Who's There On Halloween?</td>\n",
       "      <td>halloween encourages readers play along clues ...</td>\n",
       "      <td>Children's Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Foreclosure Investing For Dummies</td>\n",
       "      <td>make foreclosure investing work practical easy...</td>\n",
       "      <td>Business &amp; Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>The Raven Room</td>\n",
       "      <td>searing erotic thriller perfect tantalized tor...</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6946 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                    Drowned Wednesday   \n",
       "1                        The Lost Hero   \n",
       "2            The Eyes of the Overworld   \n",
       "3                      Magic's Promise   \n",
       "4                       Taran Wanderer   \n",
       "..                                 ...   \n",
       "837                       Pretty Girls   \n",
       "838                     Go! All in One   \n",
       "839          Who's There On Halloween?   \n",
       "840  Foreclosure Investing For Dummies   \n",
       "841                     The Raven Room   \n",
       "\n",
       "                                           Description  \\\n",
       "0    drowned wednesday first trustee among morrow d...   \n",
       "1    book opens jason awakens school unable remembe...   \n",
       "2    cugel easily persuaded merchant fianosther att...   \n",
       "3    book opens herald mage vanyel returning countr...   \n",
       "4    taran gurgi returned caer dallben following ev...   \n",
       "..                                                 ...   \n",
       "837  child says stunning… certain book year kathy r...   \n",
       "838  ebook printed book include media website acces...   \n",
       "839  halloween encourages readers play along clues ...   \n",
       "840  make foreclosure investing work practical easy...   \n",
       "841  searing erotic thriller perfect tantalized tor...   \n",
       "\n",
       "                         genre  \n",
       "0    Science Fiction & Fantasy  \n",
       "1    Science Fiction & Fantasy  \n",
       "2    Science Fiction & Fantasy  \n",
       "3    Science Fiction & Fantasy  \n",
       "4    Science Fiction & Fantasy  \n",
       "..                         ...  \n",
       "837                   thriller  \n",
       "838           Business & Money  \n",
       "839           Children's Books  \n",
       "840           Business & Money  \n",
       "841                    romance  \n",
       "\n",
       "[6946 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_common_words(column, n=10):\n",
    "    # Tokenize and lowercase the words\n",
    "    words = word_tokenize(\" \".join(column.str.lower()))\n",
    "\n",
    "    # Remove stopwords (common words like 'the', 'and', etc.)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Calculate word frequencies\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    # Get the most common words\n",
    "    common_words = word_freq.most_common(n)\n",
    "\n",
    "    return common_words\n",
    "\n",
    "# Get most common words in the 'description' column\n",
    "most_common_words_description = most_common_words(df['description'], n=10)\n",
    "\n",
    "# Display the result\n",
    "print(\"Most common words in 'description' column:\")\n",
    "for word, count in most_common_words_description:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "thriller                      1212\n",
       "Science Fiction & Fantasy     1010\n",
       "history                        736\n",
       "science                        647\n",
       "horror                         600\n",
       "crime                          500\n",
       "romance                        276\n",
       "psychology and self-help       258\n",
       "sports                         239\n",
       "travel                         212\n",
       "Biographies & Memoirs          173\n",
       "Business & Money               173\n",
       "Children's Books               169\n",
       "Politics & Social Sciences     160\n",
       "Cookbooks, Food & Wine         151\n",
       "Crafts, Hobbies & Home         146\n",
       "Health                         143\n",
       "Teen & YA                      141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science Fiction & Fantasy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Science Fiction & Fantasy    1010\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "science    647\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "crime    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "history    736\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horror\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "horror    600\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thriller\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "thriller    1212\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psychology and self-help\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "psychology and self-help    258\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "romance    276\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "sports    239\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "travel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "travel    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biographies & Memoirs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Biographies & Memoirs    173\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookbooks, Food & Wine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Cookbooks, Food & Wine    151\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children's Books\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Children's Books    169\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teen & YA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Teen & YA    141\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Health    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crafts, Hobbies & Home\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Crafts, Hobbies & Home    146\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business & Money\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Business & Money    173\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics & Social Sciences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Politics & Social Sciences    160\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for genre in df.genre.unique().tolist():\n",
    "    print(genre)\n",
    "    display(df.query('genre == @genre').genre.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "\n",
    "def data_preprocessing(text):\n",
    "    tokens = word_tokenize(text) #Tokenization\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word) for word in tokens] #Lemmetization\n",
    "    tokens = [SnowballStemmer(language = 'english').stem(word) for word in tokens] #Stemming\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Description'].apply(data_preprocessing)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df['genre_vec'] = labelencoder.fit_transform(df['genre'])\n",
    "df['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder.inverse_transform(df['genre_vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Description'])\n",
    "y = df['genre_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test different ML models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [BernoulliNB(),MultinomialNB(),SGDClassifier(),LogisticRegression(),RandomForestClassifier(),GradientBoostingClassifier(),\n",
    "         AdaBoostClassifier(),SVC(),DummyClassifier(),ExtraTreeClassifier(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Accuracy = []\n",
    "Precision = []\n",
    "F1_Score = []\n",
    "Recall = []\n",
    "Time_Taken = []\n",
    "for model in models:\n",
    "    name = type(model).__name__\n",
    "    Name.append(name)\n",
    "    begin = time.time()\n",
    "    model.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    end = time.time()\n",
    "    Accuracy.append(accuracy_score(prediction,y_test))\n",
    "    Precision.append(precision_score(prediction,y_test,average = 'macro'))\n",
    "    Recall.append(recall_score(prediction,y_test,average = 'macro'))\n",
    "    F1_Score.append(f1_score(prediction,y_test,average = 'macro'))\n",
    "    Time_Taken.append(end-begin)\n",
    "    print(name + ' Successfully Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict = {'Name':Name,'Accuracy':Accuracy,'Precision_score':Precision,'Recall_score':Precision,\n",
    "        'F1_score':F1_Score,'Time Taken':Time_Taken}\n",
    "model_df = pd.DataFrame(Dict)\n",
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run and store best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best fitting model \n",
    "model = MultinomialNB()\n",
    "model.fit(X,y)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"model.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(model, open(filename, \"wb\"))\n",
    "\n",
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# you can use loaded model to compute predictions\n",
    "y_predicted = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks = pd.read_pickle('../assets/my_books.pkl')\n",
    "mybooks = mybooks.query('Description.notna()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks['Description_cleaned'] = mybooks['Description'].apply(clean)\n",
    "\n",
    "# data preprocessing \n",
    "mybooks['Description'] = mybooks['Description'].apply(data_preprocessing)\n",
    "mybooks['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all the categorical features of 'genre' to numerical\n",
    "nyX = cv.transform(mybooks['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use loaded model to compute predictions\n",
    "genre = loaded_model.predict(nyX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = labelencoder.inverse_transform(genre)\n",
    "print(inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks['genre'] = inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks[['Title','genre']].head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooks.genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating prediction of model \n",
    "\n",
    "It seems like a lot of books are not predicted corretly and a majority of my books are predicted as thriller. I do read a lot of thrillers but the share is too big too be true. It does seem like the initival dataset used for prediction have a substantial share of thrillers, which may cause it too predict too many books as thrillers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model \n",
    "I will try and add another dataset for training, https://github.com/uchidalab/book-dataset/tree/master/Task2, which contains 270K books from amazon with title and category name. \n",
    "\n",
    "I will have to: \n",
    "- make sure common category names between two datasets are the same \n",
    "- remove some small and unecessary categories from the amazon dataframe. \n",
    "- collect description from google api in several rounds with max 49K books each time to now exceed limit of 50K per day. \n",
    "\n",
    "Model building: \n",
    "- use similar approach and test several models: https://www.kaggle.com/code/prathameshgadekar/book-genre-prediction-nlp/notebook\n",
    "- select best predicting model "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data cleaning - run once\n",
    "amazondf = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/uchidalab/book-dataset/master/Task2/book32-listing.csv\", \n",
    "    encoding='ISO-8859-1',\n",
    "    header=None, \n",
    "    names=[\"AMAZON INDEX (ASIN)}\",\"[FILENAME]\",\"[IMAGE URL]\",\"title\",\"author\",\"[CATEGORY ID]\",\"category\"])\n",
    "amazondf = amazondf[['title', 'author', 'category']] \n",
    "\n",
    "# I remove some categories I dont feel will be books added to GR (usually fiction) and some very small categories. \n",
    "\n",
    "new_labels = {\"Travel\"        : \"travel\",\n",
    "\"Children's Books\"            : \"Children's Books\"  ,\n",
    "\"Health, Fitness & Dieting\"   : \"Health\",\n",
    "\"Business & Money\"            : \"Business & Money\"  ,\n",
    "\"Crafts, Hobbies & Home\"      : \"Crafts, Hobbies & Home\" ,\n",
    "\"Cookbooks, Food & Wine\"      : \"Cookbooks, Food & Wine\"  ,\n",
    "\"Teen & Young Adult\"          : \"Teen & YA\",\n",
    "\"History\"                     : \"history\",\n",
    "\"Sports & Outdoors\"           : \"sports\",\n",
    "\"Romance\"                     : \"romance\",\n",
    "\"Biographies & Memoirs\"       : \"Biographies & Memoirs\",\n",
    "\"Science Fiction & Fantasy\"   : \"Science Fiction & Fantasy\",\n",
    "\"Politics & Social Sciences\"  : \"Politics & Social Sciences\",\n",
    "\"Self-Help\"                   : 'psychology and self-help' ,\n",
    "\"Mystery, Thriller & Suspense\": \"thriller\"}\n",
    "\n",
    "\n",
    "amazondf = amazondf.query('category in @new_labels')\n",
    "amazondf['category'] = amazondf['category'].replace(new_labels)\n",
    "\n",
    "amazondf = amazondf.rename(columns={'category':'genre', 'title':'Title', 'author':'Author'} )\n",
    "amazondf = amazondf.drop_duplicates(subset='Title', keep='first')\n",
    "\n",
    "amazondf.to_pickle('assets/amazon_books.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
