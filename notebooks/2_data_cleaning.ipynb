{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing my own Books from Goodreads export tool\n",
    "Goodreads export using: https://www.goodreads.com/review/import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/elisealstad/Desktop/Code/mybook-dashboard'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to same place ass app.py to import programs the same way as the app\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "if 'notebooks' in current_directory:\n",
    "    parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "    os.chdir(parent_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improt packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "# Import functions from apps folder\n",
    "from apps.collect_data import *\n",
    "\n",
    "pd.set_option('max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooksgr = pd.read_csv(\"assets/goodreads_library_export.csv\")\n",
    "mybooksgr = mybooksgr.rename(columns=lambda x: x.replace(' ', '_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "Title: Ebony\n",
      "Author(s): \n",
      "Description: EBONY is the flagship magazine of Johnson Publishing. Founded in 1945 by John H. Johnson, it still maintains the highest global circulation of any African American-focused magazine.\n",
      "Published Date: 1984-11\n",
      "Page Count: 176\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_book_info(api_key, book_title):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    params = {\n",
    "        'q': book_title,\n",
    "        'key': api_key,\n",
    "        'fields': 'items(volumeInfo(title,authors,description,publishedDate,pageCount))',\n",
    "        'maxResults': 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Request was successful\n",
    "        print('success')\n",
    "        data = response.json()\n",
    "        if 'items' in data and len(data['items']) > 0:\n",
    "            # Extract information about the first book\n",
    "            book_info = data['items'][0]['volumeInfo']\n",
    "            return book_info\n",
    "        else:\n",
    "            return None  # No book found\n",
    "    else:\n",
    "        # Request failed\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Google Books API key\n",
    "api_key = 'AIzaSyAdOtm-dWnxerfUfKywpDqJxUAYBNBzkaI'\n",
    "book_title = '1984'\n",
    "\n",
    "book_info = get_book_info(api_key, book_title)\n",
    "\n",
    "if book_info:\n",
    "    print(f\"Title: {book_info.get('title')}\")\n",
    "    print(f\"Author(s): {', '.join(book_info.get('authors', []))}\")\n",
    "    print(f\"Description: {book_info.get('description')}\")\n",
    "    print(f\"Published Date: {book_info.get('publishedDate')}\")\n",
    "    print(f\"Page Count: {book_info.get('pageCount')}\")\n",
    "else:\n",
    "    print(f\"No information found for the book '{book_title}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/cf/45/580b5a6abb70530cea7f6e697227c61e0001eff75d50b897a62b66c6d3b7/aiohttp-3.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\n",
      "  Downloading multidict-6.0.4.tar.gz (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25l"
     ]
    }
   ],
   "source": [
    "pip install aiohttp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1, \n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "    book_infos = await asyncio.gather(*tasks)\n",
    "\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    for book_info in book_infos:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'YOUR_API_KEY' with your actual Google Books API key\n",
    "df = pd.DataFrame({'Title': ['1984', 'To Kill a Mockingbird'], 'Author': ['George Orwell', 'Harper Lee']})\n",
    "result = asyncio.run(book_info_add(mybooksgr.head(2), api_key))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mybooksgr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Collecting data from Google books api\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m apimydf \u001b[39m=\u001b[39m book_info_add(mybooksgr\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mybooksgr' is not defined"
     ]
    }
   ],
   "source": [
    "# Collecting data from Google books api\n",
    "apimydf = book_info_add(mybooksgr.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes \n",
    "mybooks = pd.merge(mybooksgr,\n",
    "                     apimydf,\n",
    "                     on='Title', \n",
    "                     suffixes = ('_Goodreads', '_GoogleBooks'), \n",
    "                     how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning books df\n",
    "- page count categories\n",
    "- filter if book is read of not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page count category variable\n",
    "\n",
    "def categorize_pages(number_of_pages):\n",
    "    if number_of_pages >= 100 and number_of_pages <= 249:\n",
    "        return '100-249'\n",
    "    elif number_of_pages >= 250 and number_of_pages <= 349:\n",
    "        return '250-349'\n",
    "    elif number_of_pages >= 350 and number_of_pages <= 449:\n",
    "        return '350-449'\n",
    "    elif number_of_pages >= 450 and number_of_pages <= 599:\n",
    "        return '450-599'\n",
    "    elif number_of_pages >= 600 and number_of_pages <= 749:\n",
    "        return '600-749'\n",
    "    elif number_of_pages >= 750 and number_of_pages <= 999:\n",
    "        return '750-999'\n",
    "    else:\n",
    "        return '1000+'\n",
    "\n",
    "# Apply the categorize_pages function to create the 'Page_Cat' column\n",
    "mybooks['Page_Cat'] = mybooks['Number_of_Pages'].apply(categorize_pages)\n",
    "\n",
    "# Define the desired order of categories\n",
    "category_order = ['100-249', '250-349', '350-449', '450-599', '600-749', '750-999', '1000+']\n",
    "\n",
    "# Convert the 'Page_Cat' column to a categorical variable with the specified order\n",
    "mybooks['Page_Cat'] = pd.Categorical(mybooks['Page_Cat'], categories=category_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "mybooks = mybooks.drop_duplicates(subset=['Title', 'Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year and quarter read variable \n",
    "#  Impute data_added where date_read  is na\n",
    "mybooks['Date_Read'] = np.where(mybooks['Date_Read'].isnull() & mybooks['Read_Count']==1, mybooks['Date_Added'], mybooks['Date_Read'])\n",
    "\n",
    "# Convert 'Date_Read' column to datetime type\n",
    "mybooks['Date_Read'] = pd.to_datetime(mybooks['Date_Read'], format='mixed')\n",
    "\n",
    "# Extract year and quarter from 'Date_Read' column\n",
    "mybooks['Year'] = mybooks['Date_Read'].dt.year\n",
    "mybooks['Quarter'] = mybooks['Date_Read'].dt.quarter\n",
    "\n",
    "# Create a new column combining year and quarter\n",
    "mybooks['Year_Quarter'] = np.where(mybooks['Date_Read'].notnull(), mybooks['Year'].astype(str) + '-Q' + mybooks['Quarter'].astype(str), np.nan)\n",
    "# Replace '.0' in the Year_Quarter column with an empty string\n",
    "mybooks['Year_Quarter'] = mybooks['Year_Quarter'].fillna('').str.replace('.0', '')\n",
    "\n",
    "# Convert Year_Quarter to categorical variable\n",
    "mybooks['Year_Quarter'] = pd.Categorical(mybooks['Year_Quarter'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter na in publication year and make column publication year integer \n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].fillna( 0)\n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all na is set as np.nan and not as a string variable (had this issue with one variable)\n",
    "import numpy as np\n",
    "mybooks = mybooks.replace('nan', np.nan)\n",
    "mybooks = mybooks.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mybooks.to_pickle(\"assets/my_books.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect book topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect topics for my own books from OLapi\n",
    "my_topics = get_book_topics(mybooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the topics as \n",
    "with open(\"assets/my_topics.json\", \"w\") as outfile:\n",
    "    json.dump(my_topics, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
