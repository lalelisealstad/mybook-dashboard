{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing my own Books from Goodreads export tool\n",
    "Goodreads export using: https://www.goodreads.com/review/import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/elisealstad/Desktop/Code/mybook-dashboard'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to same place ass app.py to import programs the same way as the app\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "if 'notebooks' in current_directory:\n",
    "    parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "    os.chdir(parent_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improt packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "# Import functions from apps folder\n",
    "from apps.collect_data import *\n",
    "\n",
    "pd.set_option('max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooksgr = pd.read_csv(\"assets/goodreads_library_export.csv\")\n",
    "mybooksgr = mybooksgr.rename(columns=lambda x: x.replace(' ', '_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "Title: Ebony\n",
      "Author(s): \n",
      "Description: EBONY is the flagship magazine of Johnson Publishing. Founded in 1945 by John H. Johnson, it still maintains the highest global circulation of any African American-focused magazine.\n",
      "Published Date: 1984-11\n",
      "Page Count: 176\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_book_info(api_key, book_title):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    params = {\n",
    "        'q': book_title,\n",
    "        'key': api_key,\n",
    "        'fields': 'items(volumeInfo(title,authors,description,publishedDate,pageCount))',\n",
    "        'maxResults': 1\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Request was successful\n",
    "        print('success')\n",
    "        data = response.json()\n",
    "        if 'items' in data and len(data['items']) > 0:\n",
    "            # Extract information about the first book\n",
    "            book_info = data['items'][0]['volumeInfo']\n",
    "            return book_info\n",
    "        else:\n",
    "            return None  # No book found\n",
    "    else:\n",
    "        # Request failed\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Google Books API key\n",
    "book_title = '1984'\n",
    "\n",
    "book_info = get_book_info(api_key, book_title)\n",
    "\n",
    "if book_info:\n",
    "    print(f\"Title: {book_info.get('title')}\")\n",
    "    print(f\"Author(s): {', '.join(book_info.get('authors', []))}\")\n",
    "    print(f\"Description: {book_info.get('description')}\")\n",
    "    print(f\"Published Date: {book_info.get('publishedDate')}\")\n",
    "    print(f\"Page Count: {book_info.get('pageCount')}\")\n",
    "else:\n",
    "    print(f\"No information found for the book '{book_title}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request one done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author(s)</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Page_Count</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Rating_Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kafka on the Shore</td>\n",
       "      <td>Haruki Murakami</td>\n",
       "      <td>2011-10-10</td>\n",
       "      <td>Kafka Tamura runs away from home at fifteen, u...</td>\n",
       "      <td>9781448103690</td>\n",
       "      <td>59</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Guest Cat</td>\n",
       "      <td>Takashi Hiraide</td>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>A wonderful sui generis novel about a visiting...</td>\n",
       "      <td>9780811221511</td>\n",
       "      <td>144</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>De syv søstre</td>\n",
       "      <td>Lucinda Riley</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>Fremtiden deres står skrevet i stjernene … Mai...</td>\n",
       "      <td>9788202457273</td>\n",
       "      <td>544</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Kite Runner</td>\n",
       "      <td>Khaled Hosseini</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>THE NUMBER ONE BESTSELLER 'Devastating' Daily ...</td>\n",
       "      <td>9781526634054</td>\n",
       "      <td>368</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Title        Author(s) Publish_Date  \\\n",
       "0  Kafka on the Shore  Haruki Murakami   2011-10-10   \n",
       "1       The Guest Cat  Takashi Hiraide   2014-01-28   \n",
       "2       De syv søstre    Lucinda Riley   2015-01-20   \n",
       "3     The Kite Runner  Khaled Hosseini   2020-11-12   \n",
       "\n",
       "                                         Description           ISBN  \\\n",
       "0  Kafka Tamura runs away from home at fifteen, u...  9781448103690   \n",
       "1  A wonderful sui generis novel about a visiting...  9780811221511   \n",
       "2  Fremtiden deres står skrevet i stjernene … Mai...  9788202457273   \n",
       "3  THE NUMBER ONE BESTSELLER 'Devastating' Daily ...  9781526634054   \n",
       "\n",
       "   Page_Count Categories  Average_Rating  Rating_Count Language  \n",
       "0          59    Fiction             5.0           5.0       en  \n",
       "1         144    Fiction             3.0           1.0       en  \n",
       "2         544    Fiction             NaN           NaN       no  \n",
       "3         368    Fiction             NaN           NaN       en  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "async def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Use nest_asyncio to allow running asyncio in a notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    results = await asyncio.gather(*tasks)  # Corrected placement of await\n",
    "\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    # Extract the actual results from the list\n",
    "    for book_info in results:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "\n",
    "from apps.api import api_key\n",
    "result = await book_info_add(myreads, api_key)  # Use await when calling the async function\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.async_googleapi import run_async_script\n",
    "\n",
    "results = await run_async_script(mybooksgr.sample(5))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # asyncio.run(run_async_script(myreads.sample(5)))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_book_info(df, api_key):  # Added comma here\n",
    "    \n",
    "    \n",
    "    book_names, author_names = df['Title'].tolist(), df['Author'].tolist()\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "\n",
    "    # Combine multiple book queries into a single request\n",
    "    queries = [f'intitle:{book}+inauthor:{author}' for book, author in zip(book_names, author_names)]\n",
    "\n",
    "    params = {\n",
    "        'q': '|'.join(queries),\n",
    "        'key': api_key,\n",
    "        'maxResults': len(book_names),\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language,volumeInfo/categories)'\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    for item in data.get('items', []):\n",
    "        book_info = item.get('volumeInfo', {})\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "            subjects = book_info.get('categories', [np.nan])\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language],\n",
    "                'Subjects': [\", \".join(map(str, subjects))]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "\n",
    "df = pd.DataFrame({'Title': ['1984', 'To Kill a Mockingbird'], 'Author': ['George Orwell', 'Harper Lee']})\n",
    "result = get_book_info(mybooksgr.head(2), 'AIzaSyAdOtm-dWnxerfUfKywpDqJxUAYBNBzkaI')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_book_info(book_names, author_names, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "\n",
    "    # Combine multiple book queries into a single request\n",
    "    queries = [f'intitle:{book}+inauthor:{author}' for book, author in zip(book_names, author_names)]\n",
    "\n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'q': '+'.join(queries),\n",
    "        'key': api_key,\n",
    "        'maxResults': len(book_names),\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language,volumeInfo/categories)'\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    # Check if 'items' key exists in the response\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            if 'items' in data:\n",
    "                # Print the first item's volumeInfo for further inspection\n",
    "                print(data['items'][0]['volumeInfo'])\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            else:\n",
    "                print(\"No results found.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Make the request\n",
    "result = get_book_info(mybooksgr.head(2)['Title'].tolist(), mybooksgr.head(2)['Author'].tolist(), api_key)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooksgr['ISBN'] = mybooksgr['ISBN'].str.strip('=\"')\n",
    "mybooksgr['ISBN13'] = mybooksgr['ISBN13'].str.strip('=\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_book_details(isbn_list, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    \n",
    "    # Combine multiple ISBNs into a single request\n",
    "    queries = [f'isbn:{isbn}' for isbn in isbn_list]\n",
    "    \n",
    "    params = {\n",
    "        'q': 'isbn:0553808052, isbn:0802148530',\n",
    "        'key': api_key,\n",
    "        'maxResults': len(isbn_list),\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language,volumeInfo/categories)'\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return [item.get('volumeInfo', {}) for item in data.get('items', [])]\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual Google Books API key\n",
    "isbn_list = ['0553808052', '0802148530']\n",
    "\n",
    "# Make the request\n",
    "result = get_book_details(mybooksgr.ISBN.head(2), api_key)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mybooksgr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Collecting data from Google books api\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elisealstad/Desktop/Code/mybook-dashboard/notebooks/2_data_cleaning.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m apimydf \u001b[39m=\u001b[39m book_info_add(mybooksgr\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mybooksgr' is not defined"
     ]
    }
   ],
   "source": [
    "# Collecting data from Google books api\n",
    "apimydf = book_info_add(mybooksgr.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Author_l-f</th>\n",
       "      <th>Additional_Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISBN13</th>\n",
       "      <th>My_Rating</th>\n",
       "      <th>Average_Rating</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Binding</th>\n",
       "      <th>Number_of_Pages</th>\n",
       "      <th>Year_Published</th>\n",
       "      <th>Original_Publication_Year</th>\n",
       "      <th>Date_Read</th>\n",
       "      <th>Date_Added</th>\n",
       "      <th>Bookshelves</th>\n",
       "      <th>Bookshelves_with_positions</th>\n",
       "      <th>Exclusive_Shelf</th>\n",
       "      <th>My_Review</th>\n",
       "      <th>Spoiler</th>\n",
       "      <th>Private_Notes</th>\n",
       "      <th>Read_Count</th>\n",
       "      <th>Owned_Copies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7720252</td>\n",
       "      <td>Beautiful Malice</td>\n",
       "      <td>Rebecca  James</td>\n",
       "      <td>James, Rebecca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0553808052</td>\n",
       "      <td>9780553808056</td>\n",
       "      <td>5</td>\n",
       "      <td>3.74</td>\n",
       "      <td>Bantam</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023/11/08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>read</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52715989</td>\n",
       "      <td>Writers &amp; Lovers</td>\n",
       "      <td>Lily King</td>\n",
       "      <td>King, Lily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0802148530</td>\n",
       "      <td>9780802148537</td>\n",
       "      <td>0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>Grove Press</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>324.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023/11/12</td>\n",
       "      <td>to-read</td>\n",
       "      <td>to-read (#213)</td>\n",
       "      <td>to-read</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Book_Id             Title          Author      Author_l-f  \\\n",
       "0   7720252  Beautiful Malice  Rebecca  James  James, Rebecca   \n",
       "1  52715989  Writers & Lovers       Lily King      King, Lily   \n",
       "\n",
       "  Additional_Authors        ISBN         ISBN13  My_Rating  Average_Rating  \\\n",
       "0                NaN  0553808052  9780553808056          5            3.74   \n",
       "1                NaN  0802148530  9780802148537          0            4.03   \n",
       "\n",
       "     Publisher    Binding  Number_of_Pages  Year_Published  \\\n",
       "0       Bantam  Hardcover            272.0            2010   \n",
       "1  Grove Press  Hardcover            324.0            2020   \n",
       "\n",
       "   Original_Publication_Year Date_Read  Date_Added Bookshelves  \\\n",
       "0                     2010.0       NaN  2023/11/08         NaN   \n",
       "1                     2020.0       NaN  2023/11/12     to-read   \n",
       "\n",
       "  Bookshelves_with_positions Exclusive_Shelf  My_Review  Spoiler  \\\n",
       "0                        NaN            read        NaN      NaN   \n",
       "1             to-read (#213)         to-read        NaN      NaN   \n",
       "\n",
       "   Private_Notes  Read_Count  Owned_Copies  \n",
       "0            NaN           1             0  \n",
       "1            NaN           0             0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mybooksgr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes \n",
    "mybooks = pd.merge(mybooksgr,\n",
    "                     apimydf,\n",
    "                     on='Title', \n",
    "                     suffixes = ('_Goodreads', '_GoogleBooks'), \n",
    "                     how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning books df\n",
    "- page count categories\n",
    "- filter if book is read of not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page count category variable\n",
    "\n",
    "def categorize_pages(number_of_pages):\n",
    "    if number_of_pages >= 100 and number_of_pages <= 249:\n",
    "        return '100-249'\n",
    "    elif number_of_pages >= 250 and number_of_pages <= 349:\n",
    "        return '250-349'\n",
    "    elif number_of_pages >= 350 and number_of_pages <= 449:\n",
    "        return '350-449'\n",
    "    elif number_of_pages >= 450 and number_of_pages <= 599:\n",
    "        return '450-599'\n",
    "    elif number_of_pages >= 600 and number_of_pages <= 749:\n",
    "        return '600-749'\n",
    "    elif number_of_pages >= 750 and number_of_pages <= 999:\n",
    "        return '750-999'\n",
    "    else:\n",
    "        return '1000+'\n",
    "\n",
    "# Apply the categorize_pages function to create the 'Page_Cat' column\n",
    "mybooks['Page_Cat'] = mybooks['Number_of_Pages'].apply(categorize_pages)\n",
    "\n",
    "# Define the desired order of categories\n",
    "category_order = ['100-249', '250-349', '350-449', '450-599', '600-749', '750-999', '1000+']\n",
    "\n",
    "# Convert the 'Page_Cat' column to a categorical variable with the specified order\n",
    "mybooks['Page_Cat'] = pd.Categorical(mybooks['Page_Cat'], categories=category_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "mybooks = mybooks.drop_duplicates(subset=['Title', 'Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year and quarter read variable \n",
    "#  Impute data_added where date_read  is na\n",
    "mybooks['Date_Read'] = np.where(mybooks['Date_Read'].isnull() & mybooks['Read_Count']==1, mybooks['Date_Added'], mybooks['Date_Read'])\n",
    "\n",
    "# Convert 'Date_Read' column to datetime type\n",
    "mybooks['Date_Read'] = pd.to_datetime(mybooks['Date_Read'], format='mixed')\n",
    "\n",
    "# Extract year and quarter from 'Date_Read' column\n",
    "mybooks['Year'] = mybooks['Date_Read'].dt.year\n",
    "mybooks['Quarter'] = mybooks['Date_Read'].dt.quarter\n",
    "\n",
    "# Create a new column combining year and quarter\n",
    "mybooks['Year_Quarter'] = np.where(mybooks['Date_Read'].notnull(), mybooks['Year'].astype(str) + '-Q' + mybooks['Quarter'].astype(str), np.nan)\n",
    "# Replace '.0' in the Year_Quarter column with an empty string\n",
    "mybooks['Year_Quarter'] = mybooks['Year_Quarter'].fillna('').str.replace('.0', '')\n",
    "\n",
    "# Convert Year_Quarter to categorical variable\n",
    "mybooks['Year_Quarter'] = pd.Categorical(mybooks['Year_Quarter'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter na in publication year and make column publication year integer \n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].fillna( 0)\n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all na is set as np.nan and not as a string variable (had this issue with one variable)\n",
    "import numpy as np\n",
    "mybooks = mybooks.replace('nan', np.nan)\n",
    "mybooks = mybooks.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mybooks.to_pickle(\"assets/my_books.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect book topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect topics for my own books from OLapi\n",
    "my_topics = get_book_topics(mybooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the topics as \n",
    "with open(\"assets/my_topics.json\", \"w\") as outfile:\n",
    "    json.dump(my_topics, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
