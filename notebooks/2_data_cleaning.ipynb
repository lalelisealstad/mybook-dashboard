{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing my own Books from Goodreads export tool\n",
    "Goodreads export using: https://www.goodreads.com/review/import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/elisealstad/Desktop/Code/mybook-dashboard'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set working directory to same place ass app.py to import programs the same way as the app\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "if 'notebooks' in current_directory:\n",
    "    parent_directory = os.path.abspath(os.path.join(current_directory, os.pardir))\n",
    "    os.chdir(parent_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super fast!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improt packages\n",
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "# Import functions from apps folder\n",
    "from apps.collect_data import *\n",
    "\n",
    "pd.set_option('max_colwidth', 50)\n",
    "pd.set_option('display.max_columns', 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mybooksgr = pd.read_csv(\"assets/goodreads_library_export.csv\")\n",
    "mybooksgr = mybooksgr.rename(columns=lambda x: x.replace(' ', '_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request one done\n",
      "request one done\n",
      "                                 Title        Author(s) Publish_Date  \\\n",
      "0                     Beautiful Malice    Rebecca James   2010-08-19   \n",
      "1                     Writers & Lovers        Lily King   2020-03-03   \n",
      "2                       The Guest List       Lucy Foley   2022-06-28   \n",
      "3                    The Mystery Guest       Nita Prose   2023-11-28   \n",
      "4                The Girl on the Train    Paula Hawkins   2016-07-12   \n",
      "5                    Project Hail Mary        Andy Weir   2021-05-04   \n",
      "6  The Subtle Art of Not Giving a F*ck      Mark Manson   2016-09-13   \n",
      "7        The Lottery and Other Stories  Shirley Jackson   2009-10-01   \n",
      "\n",
      "                                         Description           ISBN  \\\n",
      "0  So. Were you glad, deep down? Were you glad to...  9780571255306   \n",
      "1  #ReadWithJenna Book Club Pick as Featured on T...  9780802148551   \n",
      "2  A REESE'S BOOK CLUB PICK THE NEW YORK TIMES BE...     0063215381   \n",
      "3  BOOK 2 OF 2: MOLLY THE MAID â€œPrepare to be swe...  9780735241312   \n",
      "4  The #1 New York Times Bestseller, USA Today Bo...  9781594634024   \n",
      "5  #1 NEW YORK TIMES BESTSELLER â€¢ From the author...  9780593135211   \n",
      "6  #1 New York Times Bestseller Over 10 million c...  9780062457738   \n",
      "7  This is the definitive collection of Shirley J...  9780141927534   \n",
      "\n",
      "   Page_Count        Categories  Average_Rating  Rating_Count Language  \n",
      "0         370  Juvenile Fiction             NaN           NaN       en  \n",
      "1         324           Fiction             NaN           NaN       en  \n",
      "2         384           Fiction             4.0           1.0       en  \n",
      "3         269           Fiction             NaN           NaN       en  \n",
      "4           0           Fiction             NaN           NaN       en  \n",
      "5         497           Fiction             5.0           2.0       en  \n",
      "6         197         Self-Help             4.0          18.0       en  \n",
      "7         320           Fiction             NaN           NaN       en  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Use nest_asyncio to allow running asyncio in a notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Create an event loop\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    # tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "    # delay = 0.2\n",
    "    # book_infos = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    \n",
    "        # Introduce a delay of 0.1 seconds between requests\n",
    "    delay = 0.1\n",
    "    book_infos = asyncio.run(asyncio.gather(*[get_book_info_wrapper(row) for _, row in df.iterrows()]))\n",
    "\n",
    "\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    for book_info in book_infos:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "result = book_info_add(mybooksgr.head(10), api_key)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sleep funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "async def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Use nest_asyncio to allow running asyncio in a notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    results = await asyncio.gather(*tasks)  # Corrected placement of await\n",
    "    print('finishe, creating dfd')\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    # Extract the actual results from the list\n",
    "    for book_info in results:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "   \n",
    "from apps.api import api_key\n",
    "result = await book_info_add(mybooksgr.sample(5), api_key)  # Use await when calling the async function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "async def get_book_info_async(session, book_name, author_name, api_key):\n",
    "    base_url = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    params = {\n",
    "        'q': f'intitle:{book_name}+inauthor:{author_name}',\n",
    "        'key': api_key,\n",
    "        'maxResults': 1,\n",
    "        'fields': 'items(volumeInfo/title,volumeInfo/authors,volumeInfo/publishedDate,volumeInfo/description,volumeInfo/industryIdentifiers,volumeInfo/pageCount,volumeInfo/categories,volumeInfo/averageRating,volumeInfo/ratingsCount,volumeInfo/language)'\n",
    "    }\n",
    "\n",
    "    async with session.get(base_url, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            if 'items' in data and len(data['items']) > 0:\n",
    "                return data['items'][0]['volumeInfo']\n",
    "            print('request one done')\n",
    "        else:\n",
    "            print(f\"Error {response.status}: {await response.text()}\")\n",
    "            return None\n",
    "\n",
    "async def get_book_info(book_name, author_name, api_key):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        return await get_book_info_async(session, book_name, author_name, api_key)\n",
    "\n",
    "async def book_info_add(df, api_key):\n",
    "    async def get_book_info_wrapper(row):\n",
    "        book_name = row['Title']\n",
    "        author_name = row['Author']\n",
    "        return await get_book_info(book_name, author_name, api_key)\n",
    "\n",
    "    # Use nest_asyncio to allow running asyncio in a notebook\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    tasks = [get_book_info_wrapper(row) for _, row in df.iterrows()]\n",
    "\n",
    "    # Run the asynchronous code\n",
    "    results = await asyncio.gather(*tasks)  # Corrected placement of await\n",
    "    print('finishe, creating dfd')\n",
    "    combined_book_info = pd.DataFrame()\n",
    "\n",
    "    # Extract the actual results from the list\n",
    "    for book_info in results:\n",
    "        if book_info:\n",
    "            authors = book_info.get('authors', [np.nan])\n",
    "            publish_date = book_info.get('publishedDate', np.nan)\n",
    "            description = book_info.get('description', np.nan)\n",
    "            identifiers = book_info.get('industryIdentifiers', [])\n",
    "            isbn = identifiers[0]['identifier'] if identifiers else np.nan\n",
    "            page_count = book_info.get('pageCount', np.nan)\n",
    "            categories = book_info.get('categories', [np.nan])\n",
    "            average_rating = book_info.get('averageRating', np.nan)\n",
    "            rating_count = book_info.get('ratingsCount', np.nan)\n",
    "            language = book_info.get('language', np.nan)\n",
    "\n",
    "            book_info_df = pd.DataFrame({\n",
    "                'Title': [book_info.get('title', np.nan)],\n",
    "                'Author(s)': [\", \".join(map(str, authors))],\n",
    "                'Publish Date': [publish_date],\n",
    "                'Description': [description],\n",
    "                'ISBN': [isbn],\n",
    "                'Page Count': [page_count],\n",
    "                'Categories': [\", \".join(map(str, categories))],\n",
    "                'Average Rating': [average_rating],\n",
    "                'Rating Count': [rating_count],\n",
    "                'Language': [language]\n",
    "            })\n",
    "            combined_book_info = pd.concat([combined_book_info, book_info_df])\n",
    "\n",
    "    # Reset the index of the combined DataFrame\n",
    "    combined_book_info = combined_book_info.reset_index(drop=True)\n",
    "    combined_book_info = combined_book_info.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "\n",
    "    return combined_book_info\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(book_info_add())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Title        Author(s) Publish_Date  \\\n",
      "0              The Couple at No 9   Claire Douglas   2021-09-16   \n",
      "1                      After Dark  Haruki Murakami   2011-10-10   \n",
      "2  The Astonishing Color of After   Emily X.R. Pan   2019-03-19   \n",
      "3             Visual Intelligence    Amy E. Herman   2016-05-03   \n",
      "4                    Cursed Bunny       Bora Chung   2022-12-06   \n",
      "\n",
      "                                         Description           ISBN  \\\n",
      "0  It was the house of their dreams. Now it's the...  9781405943413   \n",
      "1  Reality bends all the more acutely with lack o...  9781448103638   \n",
      "2  \"Emily X.R. Pan's brilliantly crafted, harrowi...     0316464015   \n",
      "3  An engrossing guide to seeingâ€”and communicatin...  9780544381063   \n",
      "4  FINALIST FOR THE 2023 NATIONAL BOOK AWARD IN T...  9781643755007   \n",
      "\n",
      "   Page_Count           Categories  Average_Rating  Rating_Count Language  \n",
      "0         338              Fiction             NaN           NaN       en  \n",
      "1         210              Fiction             4.0           1.0       en  \n",
      "2           0  Young Adult Fiction             NaN           NaN       en  \n",
      "3         336           Psychology             NaN           NaN       en  \n",
      "4         225              Fiction             NaN           NaN       en  \n"
     ]
    }
   ],
   "source": [
    "from apps.api import api_key\n",
    "import asyncio\n",
    "from apps.async_googleapi import book_info_add\n",
    "result = await book_info_add(mybooksgr.sample(5), api_key) # Use await when calling the async function\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes \n",
    "mybooks = pd.merge(mybooksgr,\n",
    "                     apimydf,\n",
    "                     on='Title', \n",
    "                     suffixes = ('_Goodreads', '_GoogleBooks'), \n",
    "                     how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning books df\n",
    "- page count categories\n",
    "- filter if book is read of not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page count category variable\n",
    "\n",
    "def categorize_pages(number_of_pages):\n",
    "    if number_of_pages >= 100 and number_of_pages <= 249:\n",
    "        return '100-249'\n",
    "    elif number_of_pages >= 250 and number_of_pages <= 349:\n",
    "        return '250-349'\n",
    "    elif number_of_pages >= 350 and number_of_pages <= 449:\n",
    "        return '350-449'\n",
    "    elif number_of_pages >= 450 and number_of_pages <= 599:\n",
    "        return '450-599'\n",
    "    elif number_of_pages >= 600 and number_of_pages <= 749:\n",
    "        return '600-749'\n",
    "    elif number_of_pages >= 750 and number_of_pages <= 999:\n",
    "        return '750-999'\n",
    "    else:\n",
    "        return '1000+'\n",
    "\n",
    "# Apply the categorize_pages function to create the 'Page_Cat' column\n",
    "mybooks['Page_Cat'] = mybooks['Number_of_Pages'].apply(categorize_pages)\n",
    "\n",
    "# Define the desired order of categories\n",
    "category_order = ['100-249', '250-349', '350-449', '450-599', '600-749', '750-999', '1000+']\n",
    "\n",
    "# Convert the 'Page_Cat' column to a categorical variable with the specified order\n",
    "mybooks['Page_Cat'] = pd.Categorical(mybooks['Page_Cat'], categories=category_order, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "mybooks = mybooks.drop_duplicates(subset=['Title', 'Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year and quarter read variable \n",
    "#  Impute data_added where date_read  is na\n",
    "mybooks['Date_Read'] = np.where(mybooks['Date_Read'].isnull() & mybooks['Read_Count']==1, mybooks['Date_Added'], mybooks['Date_Read'])\n",
    "\n",
    "# Convert 'Date_Read' column to datetime type\n",
    "mybooks['Date_Read'] = pd.to_datetime(mybooks['Date_Read'], format='mixed')\n",
    "\n",
    "# Extract year and quarter from 'Date_Read' column\n",
    "mybooks['Year'] = mybooks['Date_Read'].dt.year\n",
    "mybooks['Quarter'] = mybooks['Date_Read'].dt.quarter\n",
    "\n",
    "# Create a new column combining year and quarter\n",
    "mybooks['Year_Quarter'] = np.where(mybooks['Date_Read'].notnull(), mybooks['Year'].astype(str) + '-Q' + mybooks['Quarter'].astype(str), np.nan)\n",
    "# Replace '.0' in the Year_Quarter column with an empty string\n",
    "mybooks['Year_Quarter'] = mybooks['Year_Quarter'].fillna('').str.replace('.0', '')\n",
    "\n",
    "# Convert Year_Quarter to categorical variable\n",
    "mybooks['Year_Quarter'] = pd.Categorical(mybooks['Year_Quarter'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter na in publication year and make column publication year integer \n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].fillna( 0)\n",
    "mybooks['Original_Publication_Year'] = mybooks['Original_Publication_Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all na is set as np.nan and not as a string variable (had this issue with one variable)\n",
    "import numpy as np\n",
    "mybooks = mybooks.replace('nan', np.nan)\n",
    "mybooks = mybooks.replace('NaN', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mybooks.to_pickle(\"assets/my_books.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect book topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect topics for my own books from OLapi\n",
    "my_topics = get_book_topics(mybooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the topics as \n",
    "with open(\"assets/my_topics.json\", \"w\") as outfile:\n",
    "    json.dump(my_topics, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
